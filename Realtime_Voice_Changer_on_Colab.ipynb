{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbbmx_Vjl0zo"
      },
      "source": [
        "Realtime Voice Changer by w-okada\n",
        "---\n",
        "\n",
        "This is a attempt to run [Realtime Voice Changer](https://github.com/w-okada/voice-changer) on Google Colab.\\\n",
        "Colab File updated by [rafacasari](https://github.com/Rafacasari)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vV1t7PBRm-o6"
      },
      "outputs": [],
      "source": [
        "# @title **Always use Colab GPU!**\n",
        "# @markdown **A GPU can be used for faster processing.**\\\n",
        "# @markdown You can check the Colab GPU running this cell.\\\n",
        "# @markdown or use the menu **Runtime** -> **Change runtime** -> **Hardware acceleration** to select a GPU, if needed.\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLypf-RLIK-w"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RhdqDSt-LfGr"
      },
      "outputs": [],
      "source": [
        "# @title **[Optional]** Setup/Start Google Drive\n",
        "# @markdown Using Google Drive can improve load times in a next version that you use Voice Changer, since it will not need to download/install everything again.\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "86wTFmqsNMnD"
      },
      "outputs": [],
      "source": [
        "# @title **[1]** Clone the repository\n",
        "# @markdown Clone the repository using this cell, this process should be really fast.\n",
        "\n",
        "!git clone --depth 1 https://github.com/w-okada/voice-changer.git &> /dev/null\n",
        "\n",
        "%cd voice-changer/server/\n",
        "print(\"\\033[92mSuccessfully cloned the repository, proceed to the next cell!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LwZAAuqxX7yY"
      },
      "outputs": [],
      "source": [
        "# @title **[2]** Install Modules\n",
        "# @markdown This cell can take a few minutes to run.\n",
        "\n",
        "!apt-get install libportaudio2 &> /dev/null\n",
        "!pip install onnxruntime-gpu uvicorn faiss-gpu fairseq jedi google-colab moviepy decorator==4.4.2 sounddevice numpy==1.23.5 pyngrok --quiet\n",
        "!pip install -r requirements.txt --no-build-isolation --quiet\n",
        "# Maybe install Tensor packages?\n",
        "#!pip install torch-tensorrt\n",
        "#!pip install TensorRT\n",
        "print(\"\\033[92mSuccessfully installed all packages!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lQxvqDH2D1MK"
      },
      "outputs": [],
      "source": [
        "# @title **[3]** Setup ngrok account\n",
        "# @markdown Setup a free account at [Ngrok](https://dashboard.ngrok.com/signup), then click [this link](https://dashboard.ngrok.com/get-started/your-authtoken) to get your auth token, copy it and place it here:\n",
        "\n",
        "NgrokToken = '' # @param {type:\"string\"}\n",
        "\n",
        "!ngrok config add-authtoken {NgrokToken}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLWQuUd7WW9U",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title **[4]** Start Server\n",
        "# @markdown **Run this cell AFTER ngrok setup!**\\\n",
        "# @markdown This cell will start the server, the first time that you run it will download the example models, so it can take a while and console may be spammed a little bit. **So be fast to open the server link.**\n",
        "import portpicker\n",
        "PORT = portpicker.pick_unused_port()\n",
        "\n",
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(PORT).public_url\n",
        "\n",
        "print(\"Your server will be available at:\")\n",
        "print(public_url)\n",
        "print(public_url)\n",
        "print(public_url)\n",
        "print(\"Starting the server in 3 seconds\")\n",
        "\n",
        "!sleep 3\n",
        "!python3 MMVCServerSIO.py \\\n",
        "  -p {PORT} \\\n",
        "  --https False \\\n",
        "  --content_vec_500 pretrain/checkpoint_best_legacy_500.pt \\\n",
        "  --content_vec_500_onnx pretrain/content_vec_500.onnx \\\n",
        "  --content_vec_500_onnx_on true \\\n",
        "  --hubert_base pretrain/hubert_base.pt \\\n",
        "  --hubert_base_jp pretrain/rinna_hubert_base_jp.pt \\\n",
        "  --hubert_soft pretrain/hubert/hubert-soft-0d54a1f4.pt \\\n",
        "  --nsf_hifigan pretrain/nsf_hifigan/model \\\n",
        "  --crepe_onnx_full pretrain/crepe_onnx_full.onnx \\\n",
        "  --crepe_onnx_tiny pretrain/crepe_onnx_tiny.onnx \\\n",
        "  --rmvpe pretrain/rmvpe.pt \\\n",
        "  --model_dir model_dir \\\n",
        "  --samples samples.json \\\n",
        "  --colab True"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
